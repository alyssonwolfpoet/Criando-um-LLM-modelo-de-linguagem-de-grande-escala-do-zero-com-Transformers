{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "train_data = dataset['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data\n",
    "train_encodings = tokenizer(train_data, return_tensors='pt', max_length=4, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50256, 50256, 50256, 50256],\n",
       "        [  796,   569, 18354,  7496],\n",
       "        [50256, 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [ 4176,   635, 12007, 47593],\n",
       "        [  679,  3111,   355,  1486],\n",
       "        [50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model config and model\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and data loader\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "train_loader = DataLoader(train_encodings, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50256, 50256, 50256, 50256],\n",
       "        [  796,   569, 18354,  7496],\n",
       "        [50256, 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [ 4176,   635, 12007, 47593],\n",
       "        [  679,  3111,   355,  1486],\n",
       "        [50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 5e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader.dataset:\n",
    "        a = train_loader.dataset[batch]\n",
    "        input_ids = train_loader.dataset['input_ids'].to(device)\n",
    "        attention_mask = train_loader.dataset['attention_mask'].to(device)\n",
    "        # print(input_ids)\n",
    "        # print(attention_mask)\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[50256, 50256, 50256, 50256],\n",
      "        [  796,   569, 18354,  7496],\n",
      "        [50256, 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 4176,   635, 12007, 47593],\n",
      "        [  679,  3111,   355,  1486],\n",
      "        [50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[0, 0, 0, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 0, 0, 0]])}\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x76e276f3f070>\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "bk = train_loader.dataset\n",
    "print(bk)\n",
    "print(train_loader)\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in bk:\n",
    "        if batch == \"input_ids\":\n",
    "            batch = bk['input_ids'][0].to(device)\n",
    "            print(batch)\n",
    "        if batch == \"attention_mask\":\n",
    "            batch = bk['attention_mask'][0].to(device)\n",
    "            print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Epoch 0: Loss nan\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Epoch 1: Loss nan\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Epoch 2: Loss nan\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Epoch 3: Loss nan\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([50256, 50256, 50256, 50256], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Epoch 4: Loss nan\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader.dataset:\n",
    "\n",
    "        input_ids = train_loader.dataset['input_ids'][0].to(device)\n",
    "        print(input_ids)\n",
    "        attention_mask = train_loader.dataset['attention_mask'][0].to(device)\n",
    "        print(attention_mask)\n",
    "        \n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == tokenizer.pad_token_id] = -100  # Ignore padding in loss calculation\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained('./meuModeloGPT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Create generator pipeline\n",
    "generator = pipeline('text-generation', model='./meuModeloGPT2', tokenizer='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qual é o significado da vida, do universo e tudo mais? toll Og Kelley1991 sailriusュ crowizzizzFu civilizedpythonFar Beautifulpher monthfect Einstein skatecknowledAbstractFun Lange clerkPROMess rmolicy Pediatrics movements\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "prompt = \"Qual é o significado da vida, do universo e tudo mais?\"\n",
    "response = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "print(response[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
