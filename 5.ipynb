{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias para o projeto\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,  # Tokenizador para o modelo GPT-2\n",
    "    GPT2Config,  # Configuração do modelo GPT-2\n",
    "    GPT2LMHeadModel,  # Modelo GPT-2 com cabeçalho de linguagem\n",
    "    Trainer,  # Treinador do modelo\n",
    "    TrainingArguments,  # Argumentos de treinamento do modelo\n",
    "    pipeline  # Pipeline para geração de texto\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset de treinamento\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "train_data = dataset['train']['text']  # Selecionar dados de treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# Criar tokenizer para o modelo GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Definir token de padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar dados de treinamento\n",
    "train_encodings = tokenizer(\n",
    "    train_data,\n",
    "    return_tensors='pt',  # Retorna tensors PyTorch\n",
    "    max_length=512,  # Tamanho máximo da sequência\n",
    "    truncation=True,  # Truncar sequências longas\n",
    "    padding='max_length'  # Preencher sequências curtas com padding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar configuração do modelo GPT-2\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,  # Tamanho do vocabulário\n",
    "    n_positions=512,  # Número de posições na sequência\n",
    "    n_ctx=512,  # Número de contextos na sequência\n",
    "    n_embd=768,  # Número de dimensões do embedding\n",
    "    n_layer=12,  # Número de camadas do modelo\n",
    "    n_head=12  # Número de cabeçalhos de atenção\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar modelo GPT-2 com cabeçalho de linguagem\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar argumentos de treinamento do modelo\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./meuModeloGPT2',  # Diretório de saída do modelo\n",
    "    num_train_epochs=5,  # Número de épocas de treinamento\n",
    "    per_device_train_batch_size=8,  # Tamanho do batch de treinamento por dispositivo\n",
    "    per_device_eval_batch_size=8,  # Tamanho do batch de avaliação por dispositivo\n",
    "    evaluation_strategy='epoch',  # Estratégia de avaliação por época\n",
    "    learning_rate=5e-5,  # Taxa de aprendizado\n",
    "    save_total_limit=2,  # Número de modelos salvos\n",
    "    save_strategy='epoch',  # Estratégia de salvamento por época\n",
    "    load_best_model_at_end=True,  # Carregar melhor modelo ao final do treinamento\n",
    "    metric_for_best_model='loss',  # Métrica para selecionar melhor modelo\n",
    "    greater_is_better=False,  # Se a métrica é melhor quando é maior\n",
    "    eval_accumulation_steps=10  # Número de passos de avaliação por época\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dataset para treinamento\n",
    "train_dataset = {'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar treinador do modelo\n",
    "trainer = Trainer(\n",
    "    model=model,  # Modelo a ser treinado\n",
    "    args=training_args,  # Argumentos de treinamento\n",
    "    train_dataset=train_dataset,  # Dataset de treinamento\n",
    "    eval_dataset=train_dataset,  # Dataset de avaliação\n",
    "    compute_metrics=lambda pred: {'loss': pred.loss}  # Função para calcular métricas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar pipeline de geração de texto\n",
    "generator = pipeline('text-generation', model='./meuModeloGPT2', tokenizer='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar texto\n",
    "prompt = \"Qual é o significado da vida, do universo e tudo mais?\"\n",
    "response = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "print(response[0]['generated_text'])  # Imprimir texto gerado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
